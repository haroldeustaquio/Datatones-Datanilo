{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/db_AGP_2019_sucesos.csv')\n",
    "df_2 = pd.read_csv('data/postID_suceso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time.1</th>\n",
       "      <th>created_time.2</th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "      <th>object_link.connections.comments.message</th>\n",
       "      <th>FECHA Y HORA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan Garc√≠a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>üßêüßê</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jueves, 18 de abril de 2019</td>\n",
       "      <td>30/12/1899 20:57:16</td>\n",
       "      <td>Exequias del ex presidente Alan Garc√≠a en \"La ...</td>\n",
       "      <td>71263708835_276236269920595</td>\n",
       "      <td>ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫</td>\n",
       "      <td>18/04/2019 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mi√©rcoles, 17 de abril de 2019</td>\n",
       "      <td>30/12/1899 07:37:30</td>\n",
       "      <td>üö® Estamos en los exteriores del Hospital de Em...</td>\n",
       "      <td>71263708835_310239669653341</td>\n",
       "      <td>ü•≥</td>\n",
       "      <td>17/04/2019 7:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan Garc√≠a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>ü§∑‚Äç‚ôÄÔ∏èü§∑‚Äç‚ôÄÔ∏èü§∑‚Äç‚ôÄÔ∏è</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan Garc√≠a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>ü§Øü§Øü§Øü§Ø</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_time.1       created_time.2  \\\n",
       "0    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "1     jueves, 18 de abril de 2019  30/12/1899 20:57:16   \n",
       "2  mi√©rcoles, 17 de abril de 2019  30/12/1899 07:37:30   \n",
       "3    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "4    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "\n",
       "                                             message  \\\n",
       "0  Velorio del ex presidente Alan Garc√≠a en la Ca...   \n",
       "1  Exequias del ex presidente Alan Garc√≠a en \"La ...   \n",
       "2  üö® Estamos en los exteriores del Hospital de Em...   \n",
       "3  Velorio del ex presidente Alan Garc√≠a en la Ca...   \n",
       "4  Velorio del ex presidente Alan Garc√≠a en la Ca...   \n",
       "\n",
       "                            id object_link.connections.comments.message  \\\n",
       "0  71263708835_377868469727477                                       üßêüßê   \n",
       "1  71263708835_276236269920595                                 ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫   \n",
       "2  71263708835_310239669653341                                        ü•≥   \n",
       "3  71263708835_377868469727477                             ü§∑‚Äç‚ôÄÔ∏èü§∑‚Äç‚ôÄÔ∏èü§∑‚Äç‚ôÄÔ∏è   \n",
       "4  71263708835_377868469727477                                     ü§Øü§Øü§Øü§Ø   \n",
       "\n",
       "       FECHA Y HORA  \n",
       "0   19/04/2019 9:16  \n",
       "1  18/04/2019 20:57  \n",
       "2   17/04/2019 7:37  \n",
       "3   19/04/2019 9:16  \n",
       "4   19/04/2019 9:16  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55006 entries, 0 to 55005\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                    Non-Null Count  Dtype \n",
      "---  ------                                    --------------  ----- \n",
      " 0   created_time.1                            55006 non-null  object\n",
      " 1   created_time.2                            55006 non-null  object\n",
      " 2   message                                   55006 non-null  object\n",
      " 3   id                                        55006 non-null  object\n",
      " 4   object_link.connections.comments.message  55006 non-null  object\n",
      " 5   FECHA Y HORA                              55006 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POST NRO</th>\n",
       "      <th>SUCESO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71263708835_310239669653341</td>\n",
       "      <td>Traslado a la Clinica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71263708835_10157689377373836</td>\n",
       "      <td>Confirmaci√≥n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71263708835_2430897753596693</td>\n",
       "      <td>Confirmaci√≥n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71263708835_10157689601593836</td>\n",
       "      <td>Confirmaci√≥n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71263708835_426911824739777</td>\n",
       "      <td>Confirmaci√≥n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        POST NRO                               SUCESO\n",
       "0    71263708835_310239669653341                Traslado a la Clinica\n",
       "1  71263708835_10157689377373836  Confirmaci√≥n de Intento de Suicidio\n",
       "2   71263708835_2430897753596693  Confirmaci√≥n de Intento de Suicidio\n",
       "3  71263708835_10157689601593836  Confirmaci√≥n de Intento de Suicidio\n",
       "4    71263708835_426911824739777  Confirmaci√≥n de Intento de Suicidio"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   POST NRO  87 non-null     object\n",
      " 1   SUCESO    87 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols\n",
    "df_1.drop(columns=['created_time.2','created_time.1'],inplace=True)\n",
    "\n",
    "# merge the both datasets\n",
    "df = df_1.merge(df_2,how='left',left_on = 'id',right_on='POST NRO')\n",
    "\n",
    "# drop redundant cols\n",
    "df.drop(columns=['id','POST NRO'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the names of the columns\n",
    "df.columns = ['post','comment','datetime','context']\n",
    "\n",
    "# order the columns\n",
    "df = df[['datetime','context','post','comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of 'datetime'\n",
    "df['datetime'] = pd.to_datetime(df['datetime'],format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0\n",
       "context     0\n",
       "post        0\n",
       "comment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nan values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1444)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated values\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation, stopwords and accents from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "df['comment'] = df['comment'].str.replace(f'[{punct}]','',regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['comment'] = df['comment'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text_without_accents = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text_without_accents\n",
    "\n",
    "df['comment'] = df['comment'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create diccionary to replace the emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_to_spanish = {\n",
    "    \"‚Äº\": \"sorpresa \",\n",
    "    \"‚Åâ\": \"duda \",\n",
    "    \"‚òù\": \"alegria \",\n",
    "    \"‚ò†\": \"peligro \",\n",
    "    \"‚òπ\": \"tristeza \",\n",
    "    \"‚ò∫\": \"feliz \",\n",
    "    \"‚ô•\": \"amor \",\n",
    "    \"‚öñ\": \"justicia \",\n",
    "    \"‚ö†\": \"advertencia \",\n",
    "    \"‚õ™\": \"iglesia \",\n",
    "    \"‚úÖ\": \"verificado \",\n",
    "    \"‚úà\": \"avi√≥n \",\n",
    "    \"‚úä\": \"ira \",\n",
    "    \"‚úã\": \"mano \",\n",
    "    \"‚úå\": \"felicidad \",\n",
    "    \"‚úç\": \"escribir \",\n",
    "    \"‚úî\": \"correcto \",\n",
    "    \"‚ú®\": \"brillo \",\n",
    "    \"‚ùå\": \"incorrecto \",\n",
    "    \"‚ùé\": \"cancelado \",\n",
    "    \"‚ùó\": \"exclamacion \",\n",
    "    \"‚≠ê\": \"estrella \",\n",
    "    \"üêÄ\": \"ira \",\n",
    "    \"üêÅ\": \"ira \",\n",
    "    \"üêë\": \"oveja \",\n",
    "    \"üêñ\": \"ira \",\n",
    "    \"üê≠\": \"ira\",\n",
    "    \"üê∑\": \"ira \",\n",
    "    \"üëä\": \"pu√±o \",\n",
    "    \"üëã\": \"saludo \",\n",
    "    \"üëå\": \"ok \",\n",
    "    \"üëç\": \"aprobar \",\n",
    "    \"üëé\": \"desaprobar \",\n",
    "    \"üëè\": \"felicidad \",\n",
    "    \"üëº\": \"angel \",\n",
    "    \"üëø\": \"diablo \",\n",
    "    \"üíÄ\": \"calavera \",\n",
    "    \"üíì\": \"corazon\",\n",
    "    \"üíî\": \"corazon roto \",\n",
    "    \"üíï\": \"corazones \",\n",
    "    \"üíñ\": \"corazon \",\n",
    "    \"üíó\": \"corazon \",\n",
    "    \"üíò\": \"corazon \",\n",
    "    \"üíö\": \"corazon \",\n",
    "    \"üíú\": \"corazon \",\n",
    "    \"üí£\": \"bomba \",\n",
    "    \"üí§\": \"dormir \",\n",
    "    \"üí•\": \"explosion \",\n",
    "    \"üí©\": \"ira \",\n",
    "    \"üí™\": \"fuerza \",\n",
    "    \"üí´\": \"mareo \",\n",
    "    \"üí≠\": \"pensamiento \",\n",
    "    \"üíØ\": \"perfecto \",\n",
    "    \"üí∞\": \"dinero \",\n",
    "    \"üí≤\": \"dolar \",\n",
    "    \"üîê\": \"cerrado \",\n",
    "    \"üî•\": \"fuego \",\n",
    "    \"üñï\": \"ira \",\n",
    "    \"üòÄ\": \"sonrisa \",\n",
    "    \"üòÅ\": \"carcajada \",\n",
    "    \"üòÇ\": \"risa \",\n",
    "    \"üòÉ\": \"alegria \",\n",
    "    \"üòÑ\": \"risa \",\n",
    "    \"üòÖ\": \"alivio \",\n",
    "    \"üòÜ\": \"risa \",\n",
    "    \"üòá\": \"angel \",\n",
    "    \"üòà\": \"ira \",\n",
    "    \"üòâ\": \"gui√±o \",\n",
    "    \"üòä\": \"contento \",\n",
    "    \"üòã\": \"sabroso \",\n",
    "    \"üòå\": \"tranquilo \",\n",
    "    \"üòç\": \"enamorado \",\n",
    "    \"üòé\": \"cool \",\n",
    "    \"üòè\": \"satisfecho \",\n",
    "    \"üòê\": \"neutral \",\n",
    "    \"üòë\": \"indiferente \",\n",
    "    \"üòí\": \"decepcionado \",\n",
    "    \"üòì\": \"sudor \",\n",
    "    \"üòî\": \"pensativo \",\n",
    "    \"üòï\": \"confuso \",\n",
    "    \"üòñ\": \"preocupado \",\n",
    "    \"üòó\": \"beso \",\n",
    "    \"üòò\": \"beso \",\n",
    "    \"üòô\": \"beso \",\n",
    "    \"üòö\": \"beso \",\n",
    "    \"üòõ\": \"alegria \",\n",
    "    \"üòú\": \"alegria \",\n",
    "    \"üòù\": \"alegria \",\n",
    "    \"üòû\": \"tristeza \",\n",
    "    \"üòü\": \"angustiado \",\n",
    "    \"üò†\": \"enojado \",\n",
    "    \"üò°\": \"furioso \",\n",
    "    \"üò¢\": \"llorar \",\n",
    "    \"üò£\": \"perseverante \",\n",
    "    \"üò§\": \"determinacin \",\n",
    "    \"üò•\": \"aliviado \",\n",
    "    \"üò¶\": \"preocupacion \",\n",
    "    \"üòß\": \"shock \",\n",
    "    \"üò®\": \"temeroso \",\n",
    "    \"üò©\": \"agotado \",\n",
    "    \"üò™\": \"somnoliento \",\n",
    "    \"üò´\": \"agotamiento \",\n",
    "    \"üò¨\": \"incomodo \",\n",
    "    \"üò≠\": \"llorar \",\n",
    "    \"üòÆ\": \"sorpresa \",\n",
    "    \"üòØ\": \"silencio \",\n",
    "    \"üò∞\": \"ansiedad \",\n",
    "    \"üò±\": \"grito \",\n",
    "    \"üò≤\": \"impactado \",\n",
    "    \"üò≥\": \"avergonzado \",\n",
    "    \"üò¥\": \"dormido \",\n",
    "    \"üòµ\": \"mareado \",\n",
    "    \"üò∂\": \"sin palabras \",\n",
    "    \"üò∑\": \"enfermo \",\n",
    "    \"üò∏\": \"gato feliz \",\n",
    "    \"üòπ\": \"gato risa \",\n",
    "    \"üòº\": \"gato malicioso \",\n",
    "    \"üòø\": \"gato triste \",\n",
    "    \"üôÅ\": \"decepcionado \",\n",
    "    \"üôÇ\": \"feliz \",\n",
    "    \"üôÉ\": \"descontento \",\n",
    "    \"üôÑ\": \"descontento \",\n",
    "    \"üôÖ\": \"prohibido \",\n",
    "    \"üôÜ\": \"ok \",\n",
    "    \"üôá\": \"reverencia \",\n",
    "    \"üôà\": \"no ver \",\n",
    "    \"üôâ\": \"no escuchar \",\n",
    "    \"üôä\": \"no hablar \",\n",
    "    \"üôã\": \"mano alzada \",\n",
    "    \"üôå\": \"victoria \",\n",
    "    \"üôè\": \"felicidad \",\n",
    "    \"üö´\": \"prohibido \",\n",
    "    \"ü§ê\": \"silencio \",\n",
    "    \"ü§ë\": \"dinero \",\n",
    "    \"ü§í\": \"enfermo \",\n",
    "    \"ü§ì\": \"nerd \",\n",
    "    \"ü§î\": \"pensativo \",\n",
    "    \"ü§ï\": \"herido \",\n",
    "    \"ü§ó\": \"abrazo \",\n",
    "    \"ü§ò\": \"rock \",\n",
    "    \"ü§û\": \"suerte \",\n",
    "    \"ü§ü\": \"amor \",\n",
    "    \"ü§°\": \"payaso \",\n",
    "    \"ü§¢\": \"asco \",\n",
    "    \"ü§£\": \"carcajada \",\n",
    "    \"ü§§\": \"baba \",\n",
    "    \"ü§•\": \"mentira \",\n",
    "    \"ü§¶\": \"frustracion \",\n",
    "    \"ü§ß\": \"estornudo \",\n",
    "    \"ü§®\": \"sospecha \",\n",
    "    \"ü§©\": \"estrellas \",\n",
    "    \"ü§™\": \"loco \",\n",
    "    \"ü§´\": \"secreto \",\n",
    "    \"ü§¨\": \"molesto \",\n",
    "    \"ü§≠\": \"sorpresa \",\n",
    "    \"ü§Æ\": \"vomito \",\n",
    "    \"ü§Ø\": \"impacto \",\n",
    "    \"ü§∂\": \"navidad \",\n",
    "    \"ü§∑\": \"duda \",\n",
    "    \"ü§π\": \"malabarista \",\n",
    "    \"ü•Ä\": \"flor muerta \",\n",
    "    \"ü•Ç\": \"brindis \",\n",
    "    \"ü•É\": \"trago \",\n",
    "    \"ü•≥\": \"celebracion \",\n",
    "    \"ü•¥\": \"mareado \",\n",
    "    \"ü•µ\": \"calor \",\n",
    "    \"ü•∂\": \"frio \",\n",
    "    \"ü•∫\": \"tristeza \",\n",
    "    \"ü¶ä\": \"ira \",\n",
    "    \"ü¶∏\": \"heroe \",\n",
    "    \"üßê\": \"curioso \",\n",
    "    \"üß†\": \"cerebro \",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to handle text and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_text_from_emojis(text):\n",
    "    list_text_without_emojis = []\n",
    "    list_text_with_emojis = []\n",
    "    \n",
    "    for char in text:\n",
    "        if char not in emoji.EMOJI_DATA:\n",
    "            list_text_without_emojis.append(char)\n",
    "        else:\n",
    "            list_text_with_emojis.append(char)\n",
    "    return \"\".join(list_text_with_emojis), \"\".join(list_text_without_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comment = df['comment'].apply(separate_text_from_emojis)\n",
    "\n",
    "emojis_in_comment, text_in_comment = [], []\n",
    "\n",
    "for a,b in new_comment:\n",
    "    emojis_in_comment.append(a)\n",
    "    text_in_comment.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_emojis_to_spanish(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    list_text = []\n",
    "    for char in text:\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            list_text.append(emoji_to_spanish.get(char, \"desconocido \"))\n",
    "        else:\n",
    "            list_text.append(char)\n",
    "    \n",
    "    return \"\".join(list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_text = []\n",
    "\n",
    "for text in emojis_in_comment:\n",
    "    emojis_text.append(translate_emojis_to_spanish(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for text_1, text_2 in zip(text_in_comment, emojis_text):\n",
    "    text.append(text_1+ ' '+ text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_comment'] = pd.Series(text)\n",
    "df['new_comment'] = df['new_comment'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_emojis(texto):\n",
    "    emojis = re.compile(\n",
    "        \"[\"                      # Rango de Unicode que incluye emojis\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticonos\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # S√≠mbolos y pictogramas miscel√°neos\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transportes y s√≠mbolos relacionados\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alquimia\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometr√≠a\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Complemento\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # S√≠mbolos y pictogramas\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Objetos miscel√°neos\n",
    "        \"\\U00002700-\\U000027BF\"  # Otros s√≠mbolos\n",
    "        \"\\U000024C2-\\U0001F251\"  # S√≠mbolos adicionales\n",
    "        \"]\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emojis.sub(r'', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_comment\"] = df[\"new_comment\"].apply(drop_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_comment\"] = df[\"new_comment\"].str.strip()\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].replace(r'^[\\.\\s]*$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_comment\"] = df[\"new_comment\"].str.strip()\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(r'^[\\.\\s]*$', '', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(r'\\d+', '', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace('√¢‚Ç¨', '', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace('httpswwwfacebookcom202767666958515posts442078129694133appfbl', '', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace('httpsmfacebookcomstoryphpstoryfbidid', '', regex=True)\n",
    "\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(\"habran\",\"abran \")\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(\"ahora\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [\n",
    "        word for word in words\n",
    "        if word.lower() not in stop_words and len(word) > 2 and not word.lower().startswith('y')\n",
    "    ]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_comment'] = df['new_comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df[\"new_comment\"] == \"\"].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv('data/espaniol_NRC.csv', index_col='Spanish Word')\n",
    "lexicon.drop(columns=['anticipacion','positivo','confianza','negativo'], inplace=True)\n",
    "\n",
    "def feelings_in_text(text):\n",
    "    feelings_count = {col: 0 for col in lexicon.columns}\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in lexicon.index:\n",
    "            feeling_values = lexicon.loc[word].values\n",
    "            for i, value in enumerate(feeling_values):\n",
    "                feelings_count[lexicon.columns[i]] += value\n",
    "\n",
    "    feelings, count = sorted(feelings_count.items(), key=lambda item: item[1], reverse=True)[0]\n",
    "    if count == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiments'] = df['new_comment'].apply(feelings_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['comment',],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

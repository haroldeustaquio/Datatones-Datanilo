{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/db_AGP_2019_sucesos.csv')\n",
    "df_2 = pd.read_csv('data/postID_suceso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time.1</th>\n",
       "      <th>created_time.2</th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "      <th>object_link.connections.comments.message</th>\n",
       "      <th>FECHA Y HORA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan GarcÃ­a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>ğŸ§ğŸ§</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jueves, 18 de abril de 2019</td>\n",
       "      <td>30/12/1899 20:57:16</td>\n",
       "      <td>Exequias del ex presidente Alan GarcÃ­a en \"La ...</td>\n",
       "      <td>71263708835_276236269920595</td>\n",
       "      <td>ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º</td>\n",
       "      <td>18/04/2019 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miÃ©rcoles, 17 de abril de 2019</td>\n",
       "      <td>30/12/1899 07:37:30</td>\n",
       "      <td>ğŸš¨ Estamos en los exteriores del Hospital de Em...</td>\n",
       "      <td>71263708835_310239669653341</td>\n",
       "      <td>ğŸ¥³</td>\n",
       "      <td>17/04/2019 7:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan GarcÃ­a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viernes, 19 de abril de 2019</td>\n",
       "      <td>30/12/1899 09:16:15</td>\n",
       "      <td>Velorio del ex presidente Alan GarcÃ­a en la Ca...</td>\n",
       "      <td>71263708835_377868469727477</td>\n",
       "      <td>ğŸ¤¯ğŸ¤¯ğŸ¤¯ğŸ¤¯</td>\n",
       "      <td>19/04/2019 9:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_time.1       created_time.2  \\\n",
       "0    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "1     jueves, 18 de abril de 2019  30/12/1899 20:57:16   \n",
       "2  miÃ©rcoles, 17 de abril de 2019  30/12/1899 07:37:30   \n",
       "3    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "4    viernes, 19 de abril de 2019  30/12/1899 09:16:15   \n",
       "\n",
       "                                             message  \\\n",
       "0  Velorio del ex presidente Alan GarcÃ­a en la Ca...   \n",
       "1  Exequias del ex presidente Alan GarcÃ­a en \"La ...   \n",
       "2  ğŸš¨ Estamos en los exteriores del Hospital de Em...   \n",
       "3  Velorio del ex presidente Alan GarcÃ­a en la Ca...   \n",
       "4  Velorio del ex presidente Alan GarcÃ­a en la Ca...   \n",
       "\n",
       "                            id object_link.connections.comments.message  \\\n",
       "0  71263708835_377868469727477                                       ğŸ§ğŸ§   \n",
       "1  71263708835_276236269920595                                 ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º   \n",
       "2  71263708835_310239669653341                                        ğŸ¥³   \n",
       "3  71263708835_377868469727477                             ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸   \n",
       "4  71263708835_377868469727477                                     ğŸ¤¯ğŸ¤¯ğŸ¤¯ğŸ¤¯   \n",
       "\n",
       "       FECHA Y HORA  \n",
       "0   19/04/2019 9:16  \n",
       "1  18/04/2019 20:57  \n",
       "2   17/04/2019 7:37  \n",
       "3   19/04/2019 9:16  \n",
       "4   19/04/2019 9:16  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55006 entries, 0 to 55005\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                    Non-Null Count  Dtype \n",
      "---  ------                                    --------------  ----- \n",
      " 0   created_time.1                            55006 non-null  object\n",
      " 1   created_time.2                            55006 non-null  object\n",
      " 2   message                                   55006 non-null  object\n",
      " 3   id                                        55006 non-null  object\n",
      " 4   object_link.connections.comments.message  55006 non-null  object\n",
      " 5   FECHA Y HORA                              55006 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POST NRO</th>\n",
       "      <th>SUCESO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71263708835_310239669653341</td>\n",
       "      <td>Traslado a la Clinica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71263708835_10157689377373836</td>\n",
       "      <td>ConfirmaciÃ³n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71263708835_2430897753596693</td>\n",
       "      <td>ConfirmaciÃ³n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71263708835_10157689601593836</td>\n",
       "      <td>ConfirmaciÃ³n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71263708835_426911824739777</td>\n",
       "      <td>ConfirmaciÃ³n de Intento de Suicidio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        POST NRO                               SUCESO\n",
       "0    71263708835_310239669653341                Traslado a la Clinica\n",
       "1  71263708835_10157689377373836  ConfirmaciÃ³n de Intento de Suicidio\n",
       "2   71263708835_2430897753596693  ConfirmaciÃ³n de Intento de Suicidio\n",
       "3  71263708835_10157689601593836  ConfirmaciÃ³n de Intento de Suicidio\n",
       "4    71263708835_426911824739777  ConfirmaciÃ³n de Intento de Suicidio"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   POST NRO  87 non-null     object\n",
      " 1   SUCESO    87 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols\n",
    "df_1.drop(columns=['created_time.2','created_time.1'],inplace=True)\n",
    "\n",
    "# merge the both datasets\n",
    "df = df_1.merge(df_2,how='left',left_on = 'id',right_on='POST NRO')\n",
    "\n",
    "# drop redundant cols\n",
    "df.drop(columns=['id','POST NRO'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the names of the columns\n",
    "df.columns = ['post','comment','datetime','context']\n",
    "\n",
    "# order the columns\n",
    "df = df[['datetime','context','post','comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of 'datetime'\n",
    "df['datetime'] = pd.to_datetime(df['datetime'],format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0\n",
       "context     0\n",
       "post        0\n",
       "comment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nan values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1444)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated values\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation, stopwords and accents from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "df['comment'] = df['comment'].str.replace(f'[{punct}]','',regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['comment'] = df['comment'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text_without_accents = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text_without_accents\n",
    "\n",
    "df['comment'] = df['comment'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create diccionary to replace the emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_to_spanish = {\n",
    "    \"â€¼\": \"sorpresa \",\n",
    "    \"â‰\": \"duda \",\n",
    "    \"â˜\": \"arriba \",\n",
    "    \"â˜ \": \"peligro \",\n",
    "    \"â˜¹\": \"triste \",\n",
    "    \"â˜º\": \"feliz \",\n",
    "    \"â™¥\": \"amor \",\n",
    "    \"âš–\": \"justicia \",\n",
    "    \"âš \": \"advertencia \",\n",
    "    \"â›ª\": \"iglesia \",\n",
    "    \"âœ…\": \"verificado \",\n",
    "    \"âœˆ\": \"aviÃ³n \",\n",
    "    \"âœŠ\": \"puÃ±o \",\n",
    "    \"âœ‹\": \"mano \",\n",
    "    \"âœŒ\": \"paz \",\n",
    "    \"âœ\": \"escribir \",\n",
    "    \"âœ”\": \"correcto \",\n",
    "    \"âœ¨\": \"brillo \",\n",
    "    \"âŒ\": \"incorrecto \",\n",
    "    \"â\": \"cancelado \",\n",
    "    \"â—\": \"exclamacion \",\n",
    "    \"â­\": \"estrella \",\n",
    "    \"ğŸ€\": \"rata \",\n",
    "    \"ğŸ\": \"raton \",\n",
    "    \"ğŸ‘\": \"oveja \",\n",
    "    \"ğŸ–\": \"cerdo \",\n",
    "    \"ğŸ­\": \"raton\",\n",
    "    \"ğŸ·\": \"cerdo \",\n",
    "    \"ğŸ‘Š\": \"puÃ±o \",\n",
    "    \"ğŸ‘‹\": \"saludo \",\n",
    "    \"ğŸ‘Œ\": \"ok \",\n",
    "    \"ğŸ‘\": \"pulgar arriba \",\n",
    "    \"ğŸ‘\": \"pulgar abajo \",\n",
    "    \"ğŸ‘\": \"aplauso \",\n",
    "    \"ğŸ‘¼\": \"angel \",\n",
    "    \"ğŸ‘¿\": \"diablo \",\n",
    "    \"ğŸ’€\": \"calavera \",\n",
    "    \"ğŸ’“\": \"corazon\",\n",
    "    \"ğŸ’”\": \"corazon roto \",\n",
    "    \"ğŸ’•\": \"corazones \",\n",
    "    \"ğŸ’–\": \"corazon \",\n",
    "    \"ğŸ’—\": \"corazon \",\n",
    "    \"ğŸ’˜\": \"corazon \",\n",
    "    \"ğŸ’š\": \"corazon \",\n",
    "    \"ğŸ’œ\": \"corazon \",\n",
    "    \"ğŸ’£\": \"bomba \",\n",
    "    \"ğŸ’¤\": \"dormir \",\n",
    "    \"ğŸ’¥\": \"explosion \",\n",
    "    \"ğŸ’©\": \"popo \",\n",
    "    \"ğŸ’ª\": \"fuerza \",\n",
    "    \"ğŸ’«\": \"mareo \",\n",
    "    \"ğŸ’­\": \"pensamiento \",\n",
    "    \"ğŸ’¯\": \"perfecto \",\n",
    "    \"ğŸ’°\": \"dinero \",\n",
    "    \"ğŸ’²\": \"dolar \",\n",
    "    \"ğŸ”\": \"cerrado \",\n",
    "    \"ğŸ”¥\": \"fuego \",\n",
    "    \"ğŸ–•\": \"dedo_medio \",\n",
    "    \"ğŸ˜€\": \"sonrisa \",\n",
    "    \"ğŸ˜\": \"carcajada \",\n",
    "    \"ğŸ˜‚\": \"risa \",\n",
    "    \"ğŸ˜ƒ\": \"alegria \",\n",
    "    \"ğŸ˜„\": \"risa \",\n",
    "    \"ğŸ˜…\": \"alivio \",\n",
    "    \"ğŸ˜†\": \"risa \",\n",
    "    \"ğŸ˜‡\": \"angel \",\n",
    "    \"ğŸ˜ˆ\": \"diablo \",\n",
    "    \"ğŸ˜‰\": \"guiÃ±o \",\n",
    "    \"ğŸ˜Š\": \"contento \",\n",
    "    \"ğŸ˜‹\": \"sabroso \",\n",
    "    \"ğŸ˜Œ\": \"tranquilo \",\n",
    "    \"ğŸ˜\": \"enamorado \",\n",
    "    \"ğŸ˜\": \"cool \",\n",
    "    \"ğŸ˜\": \"satisfecho \",\n",
    "    \"ğŸ˜\": \"neutral \",\n",
    "    \"ğŸ˜‘\": \"indiferente \",\n",
    "    \"ğŸ˜’\": \"decepcionado \",\n",
    "    \"ğŸ˜“\": \"sudor \",\n",
    "    \"ğŸ˜”\": \"pensativo \",\n",
    "    \"ğŸ˜•\": \"confuso \",\n",
    "    \"ğŸ˜–\": \"preocupado \",\n",
    "    \"ğŸ˜—\": \"beso \",\n",
    "    \"ğŸ˜˜\": \"beso \",\n",
    "    \"ğŸ˜™\": \"beso \",\n",
    "    \"ğŸ˜š\": \"beso \",\n",
    "    \"ğŸ˜›\": \"lengua fuera \",\n",
    "    \"ğŸ˜œ\": \"lengua guiÃ±o \",\n",
    "    \"ğŸ˜\": \"lengua broma \",\n",
    "    \"ğŸ˜\": \"frustrado \",\n",
    "    \"ğŸ˜Ÿ\": \"angustiado \",\n",
    "    \"ğŸ˜ \": \"enojado \",\n",
    "    \"ğŸ˜¡\": \"furioso \",\n",
    "    \"ğŸ˜¢\": \"llorar \",\n",
    "    \"ğŸ˜£\": \"perseverante \",\n",
    "    \"ğŸ˜¤\": \"determinacin \",\n",
    "    \"ğŸ˜¥\": \"aliviado \",\n",
    "    \"ğŸ˜¦\": \"preocupacion \",\n",
    "    \"ğŸ˜§\": \"shock \",\n",
    "    \"ğŸ˜¨\": \"temeroso \",\n",
    "    \"ğŸ˜©\": \"agotado \",\n",
    "    \"ğŸ˜ª\": \"somnoliento \",\n",
    "    \"ğŸ˜«\": \"agotamiento \",\n",
    "    \"ğŸ˜¬\": \"incomodo \",\n",
    "    \"ğŸ˜­\": \"llorar \",\n",
    "    \"ğŸ˜®\": \"sorpresa \",\n",
    "    \"ğŸ˜¯\": \"silencio \",\n",
    "    \"ğŸ˜°\": \"ansiedad \",\n",
    "    \"ğŸ˜±\": \"grito \",\n",
    "    \"ğŸ˜²\": \"impactado \",\n",
    "    \"ğŸ˜³\": \"avergonzado \",\n",
    "    \"ğŸ˜´\": \"dormido \",\n",
    "    \"ğŸ˜µ\": \"mareado \",\n",
    "    \"ğŸ˜¶\": \"sin palabras \",\n",
    "    \"ğŸ˜·\": \"enfermo \",\n",
    "    \"ğŸ˜¸\": \"gato feliz \",\n",
    "    \"ğŸ˜¹\": \"gato risa \",\n",
    "    \"ğŸ˜¼\": \"gato malicioso \",\n",
    "    \"ğŸ˜¿\": \"gato triste \",\n",
    "    \"ğŸ™\": \"decepcionado \",\n",
    "    \"ğŸ™‚\": \"feliz \",\n",
    "    \"ğŸ™ƒ\": \"al reves \",\n",
    "    \"ğŸ™„\": \"ojo volteado \",\n",
    "    \"ğŸ™…\": \"prohibido \",\n",
    "    \"ğŸ™†\": \"ok \",\n",
    "    \"ğŸ™‡\": \"reverencia \",\n",
    "    \"ğŸ™ˆ\": \"no ver \",\n",
    "    \"ğŸ™‰\": \"no escuchar \",\n",
    "    \"ğŸ™Š\": \"no hablar \",\n",
    "    \"ğŸ™‹\": \"mano alzada \",\n",
    "    \"ğŸ™Œ\": \"victoria \",\n",
    "    \"ğŸ™\": \"oracion \",\n",
    "    \"ğŸš«\": \"prohibido \",\n",
    "    \"ğŸ¤\": \"silencio \",\n",
    "    \"ğŸ¤‘\": \"dinero \",\n",
    "    \"ğŸ¤’\": \"enfermo \",\n",
    "    \"ğŸ¤“\": \"nerd \",\n",
    "    \"ğŸ¤”\": \"pensativo \",\n",
    "    \"ğŸ¤•\": \"herido \",\n",
    "    \"ğŸ¤—\": \"abrazo \",\n",
    "    \"ğŸ¤˜\": \"rock \",\n",
    "    \"ğŸ¤\": \"cruzar dedos \",\n",
    "    \"ğŸ¤Ÿ\": \"te_amo \",\n",
    "    \"ğŸ¤¡\": \"payaso \",\n",
    "    \"ğŸ¤¢\": \"asco \",\n",
    "    \"ğŸ¤£\": \"carcajada \",\n",
    "    \"ğŸ¤¤\": \"baba \",\n",
    "    \"ğŸ¤¥\": \"mentira \",\n",
    "    \"ğŸ¤¦\": \"frustracion \",\n",
    "    \"ğŸ¤§\": \"estornudo \",\n",
    "    \"ğŸ¤¨\": \"sospecha \",\n",
    "    \"ğŸ¤©\": \"estrellas \",\n",
    "    \"ğŸ¤ª\": \"loco \",\n",
    "    \"ğŸ¤«\": \"secreto \",\n",
    "    \"ğŸ¤¬\": \"molesto \",\n",
    "    \"ğŸ¤­\": \"sorpresa \",\n",
    "    \"ğŸ¤®\": \"vomito \",\n",
    "    \"ğŸ¤¯\": \"impacto \",\n",
    "    \"ğŸ¤¶\": \"navidad \",\n",
    "    \"ğŸ¤·\": \"duda \",\n",
    "    \"ğŸ¤¹\": \"malabarista \",\n",
    "    \"ğŸ¥€\": \"flor muerta \",\n",
    "    \"ğŸ¥‚\": \"brindis \",\n",
    "    \"ğŸ¥ƒ\": \"trago \",\n",
    "    \"ğŸ¥³\": \"celebracion \",\n",
    "    \"ğŸ¥´\": \"mareado \",\n",
    "    \"ğŸ¥µ\": \"calor \",\n",
    "    \"ğŸ¥¶\": \"frio \",\n",
    "    \"ğŸ¥º\": \"suplicar \",\n",
    "    \"ğŸ¦Š\": \"zorro \",\n",
    "    \"ğŸ¦¸\": \"heroe \",\n",
    "    \"ğŸ§\": \"curioso \",\n",
    "    \"ğŸ§ \": \"cerebro \",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to handle text and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_text_from_emojis(text):\n",
    "    list_text_without_emojis = []\n",
    "    list_text_with_emojis = []\n",
    "    \n",
    "    for char in text:\n",
    "        if char not in emoji.EMOJI_DATA:\n",
    "            list_text_without_emojis.append(char)\n",
    "        else:\n",
    "            list_text_with_emojis.append(char)\n",
    "    return \"\".join(list_text_with_emojis), \"\".join(list_text_without_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comment = df['comment'].apply(separate_text_from_emojis)\n",
    "\n",
    "emojis_in_comment, text_in_comment = [], []\n",
    "\n",
    "for a,b in new_comment:\n",
    "    emojis_in_comment.append(a)\n",
    "    text_in_comment.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_emojis_to_spanish(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    list_text = []\n",
    "    for char in text:\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            list_text.append(emoji_to_spanish.get(char, \"desconocido \"))\n",
    "        else:\n",
    "            list_text.append(char)\n",
    "    \n",
    "    return \"\".join(list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_text = []\n",
    "\n",
    "for text in emojis_in_comment:\n",
    "    emojis_text.append(translate_emojis_to_spanish(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for text_1, text_2 in zip(text_in_comment, emojis_text):\n",
    "    text.append(text_1+ ' '+ text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_comment'] = pd.Series(text)\n",
    "df['new_comment'] = df['new_comment'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_emojis(texto):\n",
    "    emojis = re.compile(\n",
    "        \"[\"                      # Rango de Unicode que incluye emojis\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticonos\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # SÃ­mbolos y pictogramas miscelÃ¡neos\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transportes y sÃ­mbolos relacionados\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alquimia\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # GeometrÃ­a\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Complemento\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # SÃ­mbolos y pictogramas\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Objetos miscelÃ¡neos\n",
    "        \"\\U00002700-\\U000027BF\"  # Otros sÃ­mbolos\n",
    "        \"\\U000024C2-\\U0001F251\"  # SÃ­mbolos adicionales\n",
    "        \"]\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emojis.sub(r'', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_comment\"] = df[\"new_comment\"].apply(drop_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_comment\"] = df[\"new_comment\"].str.strip()\n",
    "df[\"new_comment\"] = df[\"new_comment\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "df[\"new_comment\"] = df[\"new_comment\"].replace(r'^[\\.\\s]*$', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lexicon = pd.read_csv('data/espaniol_NRC.csv', index_col='Spanish Word')\n",
    "lexicon.drop(columns=['anticipacion','positivo','confianza','negativo'], inplace=True)\n",
    "\n",
    "def feelings_in_text(text):\n",
    "    feelings_count = {col: 0 for col in lexicon.columns}\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in lexicon.index:\n",
    "            feeling_values = lexicon.loc[word].values\n",
    "            for i, value in enumerate(feeling_values):\n",
    "                feelings_count[lexicon.columns[i]] += value\n",
    "\n",
    "    feelings, count = sorted(feelings_count.items(), key=lambda item: item[1], reverse=True)[0]\n",
    "    if count == 0:\n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = df['new_comment'].apply(feelings_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiments'] = temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['comment',],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_words(text):\n",
    "    words = ['ahora','q','x']\n",
    "    for word in words:\n",
    "        text = text.replace(word,'')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_comment'] = df['new_comment'].apply(drop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
